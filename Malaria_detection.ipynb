{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.callbacks import TensorBoard # type: ignore\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Infected-or-not_infected-CNN-{}\".format(int(time.time()))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir = 'logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into train and test sets successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Set the paths to your infected and uninfected image directories\n",
    "infected_dir = \"cell_images 2/Parasitized\"\n",
    "uninfected_dir = \"cell_images 2/Uninfected\"\n",
    "\n",
    "# Create main data directory\n",
    "main_data_dir = \"/Users/yb/Coding_Projects/cell_images 2\"\n",
    "os.makedirs(main_data_dir, exist_ok=True)\n",
    "\n",
    "# Create train and test directories\n",
    "train_dir = os.path.join(main_data_dir, \"Train\")\n",
    "test_dir = os.path.join(main_data_dir, \"Test\")\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Create infected and uninfected subdirectories in train and test directories\n",
    "train_infected_dir = os.path.join(train_dir, \"Infected\")\n",
    "train_uninfected_dir = os.path.join(train_dir, \"Uninfected\")\n",
    "test_infected_dir = os.path.join(test_dir, \"Infected\")\n",
    "test_uninfected_dir = os.path.join(test_dir, \"Uninfected\")\n",
    "os.makedirs(train_infected_dir, exist_ok=True)\n",
    "os.makedirs(train_uninfected_dir, exist_ok=True)\n",
    "os.makedirs(test_infected_dir, exist_ok=True)\n",
    "os.makedirs(test_uninfected_dir, exist_ok=True)\n",
    "\n",
    "# List all infected and uninfected image filenames\n",
    "infected_images = os.listdir(infected_dir)\n",
    "uninfected_images = os.listdir(uninfected_dir)\n",
    "\n",
    "# Shuffle infected and uninfected images\n",
    "random.shuffle(infected_images)\n",
    "random.shuffle(uninfected_images)\n",
    "\n",
    "# Calculate the number of images for the test set (20%)\n",
    "num_infected_test = int(0.2 * len(infected_images))\n",
    "num_uninfected_test = int(0.2 * len(uninfected_images))\n",
    "\n",
    "# Copy images to test directories\n",
    "for i in range(num_infected_test):\n",
    "    shutil.copy(os.path.join(infected_dir, infected_images[i]), test_infected_dir)\n",
    "for i in range(num_uninfected_test):\n",
    "    shutil.copy(os.path.join(uninfected_dir, uninfected_images[i]), test_uninfected_dir)\n",
    "\n",
    "# Copy remaining images to train directories\n",
    "for i in range(num_infected_test, len(infected_images)):\n",
    "    shutil.copy(os.path.join(infected_dir, infected_images[i]), train_infected_dir)\n",
    "for i in range(num_uninfected_test, len(uninfected_images)):\n",
    "    shutil.copy(os.path.join(uninfected_dir, uninfected_images[i]), train_uninfected_dir)\n",
    "\n",
    "print(\"Data split into train and test sets successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('/Users/yb/Coding_Projects/cell_images 2/Train',\n",
    "                                                 target_size = (100, 100),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('/Users/yb/Coding_Projects/cell_images 2/Test',\n",
    "                                            target_size = (100, 100),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu', input_shape=[100, 100, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=8, kernel_size=3, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 50ms/step - accuracy: 0.6408 - loss: 0.6173 - val_accuracy: 0.9026 - val_loss: 0.2420\n",
      "Epoch 2/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 48ms/step - accuracy: 0.9143 - loss: 0.2374 - val_accuracy: 0.9234 - val_loss: 0.2140\n",
      "Epoch 3/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 46ms/step - accuracy: 0.9314 - loss: 0.2009 - val_accuracy: 0.9416 - val_loss: 0.1819\n",
      "Epoch 4/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 42ms/step - accuracy: 0.9343 - loss: 0.1922 - val_accuracy: 0.9323 - val_loss: 0.2162\n",
      "Epoch 5/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 42ms/step - accuracy: 0.9391 - loss: 0.1824 - val_accuracy: 0.9492 - val_loss: 0.1754\n",
      "Epoch 6/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 42ms/step - accuracy: 0.9416 - loss: 0.1729 - val_accuracy: 0.9507 - val_loss: 0.1812\n",
      "Epoch 7/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9463 - loss: 0.1646 - val_accuracy: 0.9523 - val_loss: 0.1612\n",
      "Epoch 8/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 42ms/step - accuracy: 0.9467 - loss: 0.1609 - val_accuracy: 0.9541 - val_loss: 0.1646\n",
      "Epoch 9/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 42ms/step - accuracy: 0.9516 - loss: 0.1527 - val_accuracy: 0.9530 - val_loss: 0.1582\n",
      "Epoch 10/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9492 - loss: 0.1526 - val_accuracy: 0.9536 - val_loss: 0.1711\n",
      "Epoch 11/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9556 - loss: 0.1404 - val_accuracy: 0.9488 - val_loss: 0.1657\n",
      "Epoch 12/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 44ms/step - accuracy: 0.9517 - loss: 0.1445 - val_accuracy: 0.9534 - val_loss: 0.1501\n",
      "Epoch 13/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9554 - loss: 0.1347 - val_accuracy: 0.9503 - val_loss: 0.1564\n",
      "Epoch 14/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9545 - loss: 0.1359 - val_accuracy: 0.9572 - val_loss: 0.1575\n",
      "Epoch 15/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9531 - loss: 0.1360 - val_accuracy: 0.9523 - val_loss: 0.1509\n",
      "Epoch 16/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9535 - loss: 0.1392 - val_accuracy: 0.9550 - val_loss: 0.1595\n",
      "Epoch 17/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 44ms/step - accuracy: 0.9523 - loss: 0.1382 - val_accuracy: 0.9536 - val_loss: 0.1665\n",
      "Epoch 18/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 44ms/step - accuracy: 0.9569 - loss: 0.1243 - val_accuracy: 0.9554 - val_loss: 0.1390\n",
      "Epoch 19/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 44ms/step - accuracy: 0.9565 - loss: 0.1277 - val_accuracy: 0.9536 - val_loss: 0.1479\n",
      "Epoch 20/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 44ms/step - accuracy: 0.9600 - loss: 0.1206 - val_accuracy: 0.9525 - val_loss: 0.1484\n",
      "Epoch 21/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9569 - loss: 0.1220 - val_accuracy: 0.9570 - val_loss: 0.1432\n",
      "Epoch 22/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9596 - loss: 0.1148 - val_accuracy: 0.9566 - val_loss: 0.1393\n",
      "Epoch 23/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9601 - loss: 0.1159 - val_accuracy: 0.9583 - val_loss: 0.1347\n",
      "Epoch 24/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 45ms/step - accuracy: 0.9582 - loss: 0.1202 - val_accuracy: 0.9530 - val_loss: 0.1476\n",
      "Epoch 25/25\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 43ms/step - accuracy: 0.9589 - loss: 0.1193 - val_accuracy: 0.9499 - val_loss: 0.1521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x31b31e630>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = training_set, validation_data = test_set, epochs = 25, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "The image contains a malaria-infected cell.\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('/Users/yb/Coding_Projects/asi-04-00082-g001.png', target_size=(100, 100))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "test_image /= 255.  # Normalize pixel values\n",
    "\n",
    "# Make predictions\n",
    "result = model.predict(test_image)\n",
    "# Print the result\n",
    "if result[0][0] >= 0.5:\n",
    "    print('The image does not contain a malaria-infected cell.')\n",
    "else:    \n",
    "    print('The image contains a malaria-infected cell.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
